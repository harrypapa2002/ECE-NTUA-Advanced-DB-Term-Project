{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f578b2c",
   "metadata": {},
   "source": [
    "# Query 3: Income and Crime Analysis\n",
    "\n",
    "## Description\n",
    "Using the 2010 Census data for population and the 2015 Census data for household income, this analysis aims to compute the following for each area in Los Angeles:\n",
    "1. **Average Annual Income Per Person**\n",
    "2. **Ratio of Total Number of Crimes Per Person**\n",
    "\n",
    "The results are consolidated into a table for easy interpretation.\n",
    "\n",
    "Different join strategies (`BROADCAST`, `MERGE`, `SHUFFLE_HASH`, `SHUFFLE_REPLICATE_NL`) are experimented with using Spark's `hint` and `explain` methods to understand the Catalyst optimizer's behavior. The performance of each strategy is measured and compared to determine the most suitable join strategy for this scenario.\n",
    "\n",
    "Finally, the results are saved as CSV files for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eee3176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>2887</td><td>application_1732639283265_2846</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2846/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-80.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2846_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as spark_sum, col, expr, regexp_replace, round as spark_round, lower\n",
    "from pyspark.sql.window import Window\n",
    "from sedona.spark import SedonaContext\n",
    "import time\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query 3: Income and Crime Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize Sedona\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Function to measure execution time\n",
    "def measure_execution_time(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    results = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time\n",
    "    return exec_time, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76d0917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load Crime Data ---\n",
    "crime_data_2010_2019 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "crime_data_2020_present = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Union Crime Data\n",
    "crime_df = crime_data_2010_2019.union(crime_data_2020_present) \\\n",
    "    .filter((col(\"LAT\") != 0) | (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"geom\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"geom\")\n",
    "\n",
    "# --- Load GeoJSON Census Blocks ---\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Flatten properties into columns\n",
    "flattened_df = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in blocks_df.schema[\"properties\"].dataType.fieldNames()]\n",
    "    + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Filter for Los Angeles\n",
    "population_df = flattened_df.filter(col(\"CITY\") == \"Los Angeles\").select(\n",
    "    col(\"COMM\"),\n",
    "    col(\"ZCTA10\").alias(\"ZIPCODE\"),\n",
    "    col(\"POP_2010\").alias(\"POPULATION\"),\n",
    "    col(\"HOUSING10\").alias(\"HOUSING_UNITS\"),\n",
    "    col(\"geometry\")\n",
    ")\n",
    "\n",
    "# --- Load Income Data ---\n",
    "income_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Clean Income Data\n",
    "income_data_cleaned = income_df.withColumn(\"ZIPCODE\", col(\"Zip Code\")) \\\n",
    "    .withColumn(\n",
    "        \"MEDIAN_INCOME\",\n",
    "        regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    "    ) \\\n",
    "    .select(\"ZIPCODE\", \"MEDIAN_INCOME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73577d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Join Strategy: broadcast\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [ZIPCODE#377, COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "   +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "      :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "      :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "      :     +- Generate explode(features#232), false, [features#240]\n",
      "      :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "      :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=7957]\n",
      "         +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "            +- Filter isnotnull(Zip Code#403)\n",
      "               +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|ZIPCODE|         COMM|POPULATION|HOUSING_UNITS|            geometry|MEDIAN_INCOME|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|  90732|    San Pedro|        69|           26|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       120|           70|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       240|           86|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90732|    San Pedro|        75|           29|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       246|           80|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       180|           87|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|       103|            2|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.27...|      50879.0|\n",
      "|  90731|    San Pedro|       111|           43|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         3|            1|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|  Harbor City|       150|           53|POLYGON ((-118.29...|      50879.0|\n",
      "|  90744|   Wilmington|       651|          132|POLYGON ((-118.27...|      41569.0|\n",
      "|  90744|   Wilmington|       206|           50|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        34|           12|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        67|           22|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        43|           14|POLYGON ((-118.26...|      41569.0|\n",
      "|  90016|Baldwin Hills|         0|            0|POLYGON ((-118.37...|      38330.0|\n",
      "|  90731|    San Pedro|       260|          108|POLYGON ((-118.29...|      50879.0|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Join Strategy: merge\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [ZIPCODE#377, COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "   +- SortMergeJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner\n",
      "      :- Sort [cast(ZIPCODE#377 as int) ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(cast(ZIPCODE#377 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=8214]\n",
      "      :     +- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "      :        +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "      :           +- Generate explode(features#232), false, [features#240]\n",
      "      :              +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "      :                 +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "      +- Sort [ZIPCODE#409 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(ZIPCODE#409, 1000), ENSURE_REQUIREMENTS, [plan_id=8215]\n",
      "            +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "               +- Filter isnotnull(Zip Code#403)\n",
      "                  +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+-------+-----------------+----------+-------------+--------------------+-------------+\n",
      "|ZIPCODE|             COMM|POPULATION|HOUSING_UNITS|            geometry|MEDIAN_INCOME|\n",
      "+-------+-----------------+----------+-------------+--------------------+-------------+\n",
      "|  90008|     Leimert Park|         2|            1|POLYGON ((-118.32...|      36564.0|\n",
      "|  90008|    Baldwin Hills|        86|           40|POLYGON ((-118.35...|      36564.0|\n",
      "|  90008|Crenshaw District|        99|           51|POLYGON ((-118.32...|      36564.0|\n",
      "|  90008|     Leimert Park|        67|           35|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|    Baldwin Hills|       633|          275|POLYGON ((-118.36...|      36564.0|\n",
      "|  90008|    Baldwin Hills|         0|            0|POLYGON ((-118.34...|      36564.0|\n",
      "|  90008|    Baldwin Hills|       242|          109|POLYGON ((-118.34...|      36564.0|\n",
      "|  90008|    Baldwin Hills|         0|            0|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|    Baldwin Hills|         0|            0|POLYGON ((-118.35...|      36564.0|\n",
      "|  90008|    Baldwin Hills|        45|           16|POLYGON ((-118.35...|      36564.0|\n",
      "|  90008|     Leimert Park|        93|           47|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|     Leimert Park|       265|           81|POLYGON ((-118.31...|      36564.0|\n",
      "|  90008|Crenshaw District|       113|           50|POLYGON ((-118.32...|      36564.0|\n",
      "|  90008|Crenshaw District|       120|           49|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|    Baldwin Hills|        64|           32|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|     Leimert Park|       125|           67|POLYGON ((-118.32...|      36564.0|\n",
      "|  90008|     Leimert Park|         0|            0|POLYGON ((-118.33...|      36564.0|\n",
      "|  90008|     Leimert Park|         0|            0|POLYGON ((-118.32...|      36564.0|\n",
      "|  90008|    Baldwin Hills|         0|            0|POLYGON ((-118.34...|      36564.0|\n",
      "|  90008|     Leimert Park|       207|          122|POLYGON ((-118.32...|      36564.0|\n",
      "+-------+-----------------+----------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Join Strategy: shuffle_hash\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [ZIPCODE#377, COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "   +- ShuffledHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight\n",
      "      :- Exchange hashpartitioning(cast(ZIPCODE#377 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=8565]\n",
      "      :  +- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "      :     +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "      :        +- Generate explode(features#232), false, [features#240]\n",
      "      :           +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "      :              +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "      +- Exchange hashpartitioning(ZIPCODE#409, 1000), ENSURE_REQUIREMENTS, [plan_id=8566]\n",
      "         +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "            +- Filter isnotnull(Zip Code#403)\n",
      "               +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+-------+---------+----------+-------------+--------------------+-------------+\n",
      "|ZIPCODE|     COMM|POPULATION|HOUSING_UNITS|            geometry|MEDIAN_INCOME|\n",
      "+-------+---------+----------+-------------+--------------------+-------------+\n",
      "|  90069|  Melrose|       123|           84|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|  Melrose|        20|           12|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|Hollywood|        26|           23|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|Hollywood|         3|            3|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|Hollywood|        64|           35|POLYGON ((-118.39...|      78979.0|\n",
      "|  90069|  Melrose|       433|          294|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|Hollywood|         8|           10|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|  Melrose|         0|            0|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|  Melrose|       124|           85|POLYGON ((-118.36...|      78979.0|\n",
      "|  90069|  Melrose|         9|           10|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|Hollywood|        87|           59|POLYGON ((-118.39...|      78979.0|\n",
      "|  90069|Hollywood|        18|            8|POLYGON ((-118.39...|      78979.0|\n",
      "|  90069|Hollywood|       459|          266|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|Hollywood|       122|           82|POLYGON ((-118.36...|      78979.0|\n",
      "|  90069|Hollywood|        30|           15|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|Hollywood|         0|            0|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|  Melrose|       119|           80|POLYGON ((-118.37...|      78979.0|\n",
      "|  90069|Hollywood|         1|            1|POLYGON ((-118.36...|      78979.0|\n",
      "|  90069|Hollywood|       107|           80|POLYGON ((-118.38...|      78979.0|\n",
      "|  90069|Hollywood|        94|           50|POLYGON ((-118.36...|      78979.0|\n",
      "+-------+---------+----------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Join Strategy: shuffle_replicate_nl\n",
      "== Physical Plan ==\n",
      "*(3) Project [ZIPCODE#377, COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "+- CartesianProduct (cast(ZIPCODE#377 as int) = ZIPCODE#409)\n",
      "   :- *(1) Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "   :  +- *(1) Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "   :     +- *(1) Generate explode(features#232), false, [features#240]\n",
      "   :        +- *(1) Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "   :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "   +- *(2) Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "      +- *(2) Filter isnotnull(Zip Code#403)\n",
      "         +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|ZIPCODE|         COMM|POPULATION|HOUSING_UNITS|            geometry|MEDIAN_INCOME|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|  90732|    San Pedro|        69|           26|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       120|           70|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       240|           86|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90732|    San Pedro|        75|           29|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       246|           80|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       180|           87|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|       103|            2|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.27...|      50879.0|\n",
      "|  90731|    San Pedro|       111|           43|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         3|            1|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|  Harbor City|       150|           53|POLYGON ((-118.29...|      50879.0|\n",
      "|  90744|   Wilmington|       651|          132|POLYGON ((-118.27...|      41569.0|\n",
      "|  90744|   Wilmington|       206|           50|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        34|           12|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        67|           22|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        43|           14|POLYGON ((-118.26...|      41569.0|\n",
      "|  90016|Baldwin Hills|         0|            0|POLYGON ((-118.37...|      38330.0|\n",
      "|  90731|    San Pedro|       260|          108|POLYGON ((-118.29...|      50879.0|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Join Strategy: Default\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [ZIPCODE#377, COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "   +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "      :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "      :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "      :     +- Generate explode(features#232), false, [features#240]\n",
      "      :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "      :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=9005]\n",
      "         +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "            +- Filter isnotnull(Zip Code#403)\n",
      "               +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|ZIPCODE|         COMM|POPULATION|HOUSING_UNITS|            geometry|MEDIAN_INCOME|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "|  90732|    San Pedro|        69|           26|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       120|           70|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       240|           86|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.29...|      50879.0|\n",
      "|  90732|    San Pedro|        75|           29|POLYGON ((-118.31...|      84679.0|\n",
      "|  90731|    San Pedro|       246|           80|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|       180|           87|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|    San Pedro|       103|            2|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         0|            0|POLYGON ((-118.27...|      50879.0|\n",
      "|  90731|    San Pedro|       111|           43|POLYGON ((-118.28...|      50879.0|\n",
      "|  90731|    San Pedro|         3|            1|POLYGON ((-118.29...|      50879.0|\n",
      "|  90731|  Harbor City|       150|           53|POLYGON ((-118.29...|      50879.0|\n",
      "|  90744|   Wilmington|       651|          132|POLYGON ((-118.27...|      41569.0|\n",
      "|  90744|   Wilmington|       206|           50|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        34|           12|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        67|           22|POLYGON ((-118.26...|      41569.0|\n",
      "|  90744|   Wilmington|        43|           14|POLYGON ((-118.26...|      41569.0|\n",
      "|  90016|Baldwin Hills|         0|            0|POLYGON ((-118.37...|      38330.0|\n",
      "|  90731|    San Pedro|       260|          108|POLYGON ((-118.29...|      50879.0|\n",
      "+-------+-------------+----------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "=== Join Times for Population + Income ===\n",
      "broadcast: 11.00 seconds\n",
      "merge: 10.03 seconds\n",
      "shuffle_hash: 11.56 seconds\n",
      "shuffle_replicate_nl: 9.83 seconds\n",
      "default: 11.37 seconds"
     ]
    }
   ],
   "source": [
    "# Function to perform joins with different strategies and measure execution time\n",
    "def perform_join_with_strategy(population_df, income_data_cleaned, strategy_hint):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if strategy_hint:\n",
    "        income_df_hinted = income_data_cleaned.hint(strategy_hint)\n",
    "        print(f\"\\nJoin Strategy: {strategy_hint}\")\n",
    "    else:\n",
    "        income_df_hinted = income_data_cleaned\n",
    "        print(\"\\nJoin Strategy: Default\")\n",
    "    \n",
    "    # Perform the join on ZIPCODE\n",
    "    joined_df = population_df.join(\n",
    "        income_df_hinted,\n",
    "        on=\"ZIPCODE\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Explain the physical plan\n",
    "    joined_df.explain()\n",
    "    \n",
    "    # Trigger join execution\n",
    "    joined_df.show()\n",
    "    \n",
    "    \n",
    "    exec_time = time.time() - start_time\n",
    "    return exec_time, joined_df\n",
    "\n",
    "# Define join strategies to test\n",
    "join_strategies = [\"broadcast\", \"merge\", \"shuffle_hash\", \"shuffle_replicate_nl\"]\n",
    "\n",
    "# Measure execution time for each join strategy\n",
    "join_times = []\n",
    "for strategy in join_strategies:\n",
    "    exec_time, joined_df = perform_join_with_strategy(population_df, income_data_cleaned, strategy)\n",
    "    join_times.append((strategy, exec_time))\n",
    "\n",
    "# Perform default join without any hint\n",
    "exec_time_default, joined_df_default = perform_join_with_strategy(population_df, income_data_cleaned, strategy_hint=None)\n",
    "join_times.append((\"default\", exec_time_default))\n",
    "\n",
    "# Display join times\n",
    "print(\"\\n=== Join Times for Population + Income ===\")\n",
    "for strat, t in join_times:\n",
    "    print(f\"{strat}: {t:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef82cea5",
   "metadata": {},

   ],
   "source": [
    "# Perform Aggregation after Join\n",
    "def aggregate_population_income(joined_df):\n",
    "    pop_income_agg = joined_df.groupBy(\"COMM\") \\\n",
    "        .agg(\n",
    "            spark_sum(\"POPULATION\").alias(\"TOTAL_POPULATION\"),\n",
    "            spark_sum(expr(\"MEDIAN_INCOME * HOUSING_UNITS\")).alias(\"TOTAL_INCOME\"),\n",
    "            expr(\"ST_Union_Aggr(geometry) AS geometry\")\n",
    "        ) \\\n",
    "        .withColumn(\n",
    "            \"AVERAGE_INCOME_PER_PERSON\",\n",
    "            spark_round(col(\"TOTAL_INCOME\") / col(\"TOTAL_POPULATION\"), 2)\n",
    "        ) \\\n",
    "        .select(\"COMM\", \"TOTAL_POPULATION\", \"AVERAGE_INCOME_PER_PERSON\", \"geometry\")\n",
    "    \n",
    "    return pop_income_agg\n",
    "\n",
    "# Aggregate using the default joined DataFrame\n",
    "pop_income_agg = aggregate_population_income(joined_df_default)\n",
    "pop_income_agg.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb933f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spatial Join Strategy: broadcast\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastIndexJoin geom#200: geometry, RightSide, LeftSide, Inner, WITHIN ST_WITHIN(geom#200, geometry#1868)\n",
      "   :- Union\n",
      "   :  :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#200]\n",
      "   :  :  +- Filter ((NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :  :     +- FileScan csv [LAT#68,LON#69] Batched: false, DataFilters: [(NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.express..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   :  +- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2315]\n",
      "   :     +- Filter ((NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :        +- FileScan csv [LAT#142,LON#143] Batched: false, DataFilters: [(NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.expre..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   +- SpatialIndex geometry#1868: geometry, RTREE, false, false\n",
      "      +- Project [COMM#256, TOTAL_POPULATION#1865L, round((TOTAL_INCOME#1867 / cast(TOTAL_POPULATION#1865L as double)), 2) AS AVERAGE_INCOME_PER_PERSON#1892, geometry#1868]\n",
      "         +- Filter isnotnull(geometry#1868)\n",
      "            +- ObjectHashAggregate(keys=[COMM#256], functions=[sum(POPULATION#378L), sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "               +- Exchange hashpartitioning(COMM#256, 1000), ENSURE_REQUIREMENTS, [plan_id=12442]\n",
      "                  +- ObjectHashAggregate(keys=[COMM#256], functions=[partial_sum(POPULATION#378L), partial_sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), partial_st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "                     +- Project [COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "                        +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "                           :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "                           :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "                           :     +- Generate explode(features#232), false, [features#240]\n",
      "                           :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "                           :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "                           +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=12437]\n",
      "                              +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "                                 +- Filter isnotnull(Zip Code#403)\n",
      "                                    +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|                geom|              COMM|TOTAL_POPULATION|AVERAGE_INCOME_PER_PERSON|            geometry|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|POINT (-118.2695 ...|Florence-Firestone|           43638|                  8079.27|POLYGON ((-118.25...|\n",
      "|POINT (-118.3962 ...|       Westchester|           48017|                 33988.46|POLYGON ((-118.43...|\n",
      "|POINT (-118.2524 ...|           Central|           35422|                  6972.52|POLYGON ((-118.24...|\n",
      "|POINT (-118.3295 ...|         Hollywood|           62412|                 25648.05|POLYGON ((-118.33...|\n",
      "|POINT (-118.2488 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2577 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2643 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2427 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.264 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2488 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2375 ...|         Chinatown|            7677|                 14058.46|POLYGON ((-118.23...|\n",
      "|POINT (-118.2386 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2609 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.254 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2424 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.255 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2668 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2461 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2499 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2374 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Spatial Join Strategy: merge\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- RangeJoin geom#200: geometry, geometry#1868: geometry, WITHIN\n",
      "   :- Union\n",
      "   :  :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#200]\n",
      "   :  :  +- Filter ((NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :  :     +- FileScan csv [LAT#68,LON#69] Batched: false, DataFilters: [(NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.express..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   :  +- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2386]\n",
      "   :     +- Filter ((NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :        +- FileScan csv [LAT#142,LON#143] Batched: false, DataFilters: [(NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.expre..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   +- Project [COMM#256, TOTAL_POPULATION#1865L, round((TOTAL_INCOME#1867 / cast(TOTAL_POPULATION#1865L as double)), 2) AS AVERAGE_INCOME_PER_PERSON#1892, geometry#1868]\n",
      "      +- Filter isnotnull(geometry#1868)\n",
      "         +- ObjectHashAggregate(keys=[COMM#256], functions=[sum(POPULATION#378L), sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "            +- Exchange hashpartitioning(COMM#256, 1000), ENSURE_REQUIREMENTS, [plan_id=13024]\n",
      "               +- ObjectHashAggregate(keys=[COMM#256], functions=[partial_sum(POPULATION#378L), partial_sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), partial_st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "                  +- Project [COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "                     +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "                        :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "                        :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "                        :     +- Generate explode(features#232), false, [features#240]\n",
      "                        :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "                        :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=13019]\n",
      "                           +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "                              +- Filter isnotnull(Zip Code#403)\n",
      "                                 +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|                geom|              COMM|TOTAL_POPULATION|AVERAGE_INCOME_PER_PERSON|            geometry|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|POINT (-118.2695 ...|Florence-Firestone|           43638|                  8079.27|POLYGON ((-118.25...|\n",
      "|POINT (-118.3962 ...|       Westchester|           48017|                 33988.46|POLYGON ((-118.43...|\n",
      "|POINT (-118.2524 ...|           Central|           35422|                  6972.52|POLYGON ((-118.24...|\n",
      "|POINT (-118.3295 ...|         Hollywood|           62412|                 25648.05|POLYGON ((-118.33...|\n",
      "|POINT (-118.2488 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2577 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2643 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2427 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.264 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2488 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2375 ...|         Chinatown|            7677|                 14058.46|POLYGON ((-118.23...|\n",
      "|POINT (-118.2386 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2609 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.254 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2424 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.255 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2668 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2461 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2499 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2374 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Spatial Join Strategy: shuffle_hash\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- RangeJoin geom#200: geometry, geometry#1868: geometry, WITHIN\n",
      "   :- Union\n",
      "   :  :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#200]\n",
      "   :  :  +- Filter ((NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :  :     +- FileScan csv [LAT#68,LON#69] Batched: false, DataFilters: [(NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.express..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   :  +- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2457]\n",
      "   :     +- Filter ((NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :        +- FileScan csv [LAT#142,LON#143] Batched: false, DataFilters: [(NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.expre..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   +- Project [COMM#256, TOTAL_POPULATION#1865L, round((TOTAL_INCOME#1867 / cast(TOTAL_POPULATION#1865L as double)), 2) AS AVERAGE_INCOME_PER_PERSON#1892, geometry#1868]\n",
      "      +- Filter isnotnull(geometry#1868)\n",
      "         +- ObjectHashAggregate(keys=[COMM#256], functions=[sum(POPULATION#378L), sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "            +- Exchange hashpartitioning(COMM#256, 1000), ENSURE_REQUIREMENTS, [plan_id=13590]\n",
      "               +- ObjectHashAggregate(keys=[COMM#256], functions=[partial_sum(POPULATION#378L), partial_sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), partial_st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "                  +- Project [COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "                     +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "                        :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "                        :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "                        :     +- Generate explode(features#232), false, [features#240]\n",
      "                        :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "                        :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=13585]\n",
      "                           +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "                              +- Filter isnotnull(Zip Code#403)\n",
      "                                 +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|                geom|              COMM|TOTAL_POPULATION|AVERAGE_INCOME_PER_PERSON|            geometry|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|POINT (-118.2695 ...|Florence-Firestone|           43638|                  8079.27|POLYGON ((-118.25...|\n",
      "|POINT (-118.3962 ...|       Westchester|           48017|                 33988.46|POLYGON ((-118.43...|\n",
      "|POINT (-118.2524 ...|           Central|           35422|                  6972.52|POLYGON ((-118.24...|\n",
      "|POINT (-118.3295 ...|         Hollywood|           62412|                 25648.05|POLYGON ((-118.33...|\n",
      "|POINT (-118.2488 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2577 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2643 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2427 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.264 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2488 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2375 ...|         Chinatown|            7677|                 14058.46|POLYGON ((-118.23...|\n",
      "|POINT (-118.2386 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2609 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.254 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2424 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.255 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2668 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2461 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2499 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2374 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Spatial Join Strategy: shuffle_replicate_nl\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- RangeJoin geom#200: geometry, geometry#1868: geometry, WITHIN\n",
      "   :- Union\n",
      "   :  :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#200]\n",
      "   :  :  +- Filter ((NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :  :     +- FileScan csv [LAT#68,LON#69] Batched: false, DataFilters: [(NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.express..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   :  +- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2528]\n",
      "   :     +- Filter ((NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :        +- FileScan csv [LAT#142,LON#143] Batched: false, DataFilters: [(NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.expre..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   +- Project [COMM#256, TOTAL_POPULATION#1865L, round((TOTAL_INCOME#1867 / cast(TOTAL_POPULATION#1865L as double)), 2) AS AVERAGE_INCOME_PER_PERSON#1892, geometry#1868]\n",
      "      +- Filter isnotnull(geometry#1868)\n",
      "         +- ObjectHashAggregate(keys=[COMM#256], functions=[sum(POPULATION#378L), sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "            +- Exchange hashpartitioning(COMM#256, 1000), ENSURE_REQUIREMENTS, [plan_id=14156]\n",
      "               +- ObjectHashAggregate(keys=[COMM#256], functions=[partial_sum(POPULATION#378L), partial_sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), partial_st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "                  +- Project [COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "                     +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "                        :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "                        :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "                        :     +- Generate explode(features#232), false, [features#240]\n",
      "                        :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "                        :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=14151]\n",
      "                           +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "                              +- Filter isnotnull(Zip Code#403)\n",
      "                                 +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|                geom|              COMM|TOTAL_POPULATION|AVERAGE_INCOME_PER_PERSON|            geometry|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|POINT (-118.2695 ...|Florence-Firestone|           43638|                  8079.27|POLYGON ((-118.25...|\n",
      "|POINT (-118.3962 ...|       Westchester|           48017|                 33988.46|POLYGON ((-118.43...|\n",
      "|POINT (-118.2524 ...|           Central|           35422|                  6972.52|POLYGON ((-118.24...|\n",
      "|POINT (-118.3295 ...|         Hollywood|           62412|                 25648.05|POLYGON ((-118.33...|\n",
      "|POINT (-118.2488 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2577 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2643 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2427 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.264 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2488 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2375 ...|         Chinatown|            7677|                 14058.46|POLYGON ((-118.23...|\n",
      "|POINT (-118.2386 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2609 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.254 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2424 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.255 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2668 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2461 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2499 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2374 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Spatial Join Strategy: Default\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- RangeJoin geom#200: geometry, geometry#1868: geometry, WITHIN\n",
      "   :- Union\n",
      "   :  :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#200]\n",
      "   :  :  +- Filter ((NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :  :     +- FileScan csv [LAT#68,LON#69] Batched: false, DataFilters: [(NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.express..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   :  +- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2599]\n",
      "   :     +- Filter ((NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "   :        +- FileScan csv [LAT#142,LON#143] Batched: false, DataFilters: [(NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)), isnotnull( **org.apache.spark.sql.sedona_sql.expre..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_D..., PartitionFilters: [], PushedFilters: [Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<LAT:double,LON:double>\n",
      "   +- Project [COMM#256, TOTAL_POPULATION#1865L, round((TOTAL_INCOME#1867 / cast(TOTAL_POPULATION#1865L as double)), 2) AS AVERAGE_INCOME_PER_PERSON#1892, geometry#1868]\n",
      "      +- Filter isnotnull(geometry#1868)\n",
      "         +- ObjectHashAggregate(keys=[COMM#256], functions=[sum(POPULATION#378L), sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "            +- Exchange hashpartitioning(COMM#256, 1000), ENSURE_REQUIREMENTS, [plan_id=14722]\n",
      "               +- ObjectHashAggregate(keys=[COMM#256], functions=[partial_sum(POPULATION#378L), partial_sum((MEDIAN_INCOME#415 * cast(HOUSING_UNITS#379L as double))), partial_st_union_aggr(geometry#243, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@4d0b3b29, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, Some(ST_Union_Aggr))])\n",
      "                  +- Project [COMM#256, POPULATION#378L, HOUSING_UNITS#379L, geometry#243, MEDIAN_INCOME#415]\n",
      "                     +- BroadcastHashJoin [cast(ZIPCODE#377 as int)], [ZIPCODE#409], Inner, BuildRight, false\n",
      "                        :- Project [features#240.properties.COMM AS COMM#256, features#240.properties.ZCTA10 AS ZIPCODE#377, features#240.properties.POP_2010 AS POPULATION#378L, features#240.properties.HOUSING10 AS HOUSING_UNITS#379L, features#240.geometry AS geometry#243]\n",
      "                        :  +- Filter ((isnotnull(features#240.properties.CITY) AND (features#240.properties.CITY = Los Angeles)) AND isnotnull(features#240.properties.ZCTA10))\n",
      "                        :     +- Generate explode(features#232), false, [features#240]\n",
      "                        :        +- Filter ((size(features#232, true) > 0) AND isnotnull(features#232))\n",
      "                        :           +- FileScan geojson [features#232] Batched: false, DataFilters: [(size(features#232, true) > 0), isnotnull(features#232)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Block..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=14717]\n",
      "                           +- Project [Zip Code#403 AS ZIPCODE#409, cast(regexp_replace(Estimated Median Income#405, [$,], , 1) as double) AS MEDIAN_INCOME#415]\n",
      "                              +- Filter isnotnull(Zip Code#403)\n",
      "                                 +- FileScan csv [Zip Code#403,Estimated Median Income#405] Batched: false, DataFilters: [isnotnull(Zip Code#403)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|                geom|              COMM|TOTAL_POPULATION|AVERAGE_INCOME_PER_PERSON|            geometry|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "|POINT (-118.2695 ...|Florence-Firestone|           43638|                  8079.27|POLYGON ((-118.25...|\n",
      "|POINT (-118.3962 ...|       Westchester|           48017|                 33988.46|POLYGON ((-118.43...|\n",
      "|POINT (-118.2524 ...|           Central|           35422|                  6972.52|POLYGON ((-118.24...|\n",
      "|POINT (-118.3295 ...|         Hollywood|           62412|                 25648.05|POLYGON ((-118.33...|\n",
      "|POINT (-118.2488 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2577 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2643 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2427 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.264 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2488 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2375 ...|         Chinatown|            7677|                 14058.46|POLYGON ((-118.23...|\n",
      "|POINT (-118.2386 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2609 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.254 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2424 ...|      Little Tokyo|            3386|                 15281.62|POLYGON ((-118.24...|\n",
      "|POINT (-118.255 3...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2668 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2461 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "|POINT (-118.2499 ...|          Downtown|           23632|                 18522.98|POLYGON ((-118.27...|\n",
      "|POINT (-118.2374 ...|Wholesale District|           37156|                  7728.69|POLYGON ((-118.23...|\n",
      "+--------------------+------------------+----------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "=== Spatial Join Times: Crime + Population Income ===\n",
      "broadcast: 13.54 seconds\n",
      "merge: 13.47 seconds\n",
      "shuffle_hash: 13.50 seconds\n",
      "shuffle_replicate_nl: 13.42 seconds\n",
      "default: 13.42 seconds"
     ]
    }
   ],
   "source": [
    "# Function to perform spatial join with different strategies and measure execution time\n",
    "def perform_spatial_join_with_strategy(crime_df, pop_income_agg, strategy_hint):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if strategy_hint:\n",
    "        pop_income_hinted = pop_income_agg.hint(strategy_hint)\n",
    "        print(f\"\\nSpatial Join Strategy: {strategy_hint}\")\n",
    "    else:\n",
    "        pop_income_hinted = pop_income_agg\n",
    "        print(\"\\nSpatial Join Strategy: Default\")\n",
    "    \n",
    "    # Perform spatial join using ST_Within\n",
    "    joined_spatial_df = crime_df.join(\n",
    "        pop_income_hinted,\n",
    "        expr(\"ST_Within(geom, geometry)\"),\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    # Explain the physical plan\n",
    "    joined_spatial_df.explain()\n",
    "    \n",
    "    # Triger join execution\n",
    "    joined_spatial_df.show()\n",
    "    \n",
    "    exec_time = time.time() - start_time\n",
    "    return exec_time, joined_spatial_df\n",
    "\n",
    "# Define spatial join strategies to test\n",
    "spatial_join_strategies = [\"broadcast\", \"merge\", \"shuffle_hash\", \"shuffle_replicate_nl\"]\n",
    "\n",
    "# Measure execution time for each spatial join strategy\n",
    "spatial_join_times = []\n",
    "for strategy in spatial_join_strategies:\n",
    "    exec_time, joined_spatial_df = perform_spatial_join_with_strategy(crime_df, pop_income_agg, strategy)\n",
    "    spatial_join_times.append((strategy, exec_time))\n",
    "\n",
    "# Perform default spatial join without any hint\n",
    "exec_time_spatial_default, joined_spatial_df_default = perform_spatial_join_with_strategy(crime_df, pop_income_agg, strategy_hint=None)\n",
    "spatial_join_times.append((\"default\", exec_time_spatial_default))\n",
    "\n",
    "# Display spatial join times\n",
    "print(\"\\n=== Spatial Join Times: Crime + Population Income ===\")\n",
    "for strat, t in spatial_join_times:\n",
    "    print(f\"{strat}: {t:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18e4d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final DataFrame ===\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|COMM               |AVERAGE_INCOME_PER_PERSON|CRIME_RATIO_PER_PERSON|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|Thai Town          |26851.47                 |0.53                  |\n",
      "|Harvard Heights    |11820.77                 |0.78                  |\n",
      "|Valley Glen        |18271.77                 |0.55                  |\n",
      "|Sycamore Square    |30116.82                 |1.13                  |\n",
      "|Del Rey            |33675.36                 |0.56                  |\n",
      "|Lakeview Terrace   |15991.26                 |0.62                  |\n",
      "|Baldwin Hills      |17302.7                  |1.19                  |\n",
      "|Winnetka           |19638.75                 |0.67                  |\n",
      "|Toluca Woods       |24517.58                 |0.64                  |\n",
      "|Harbor City        |21383.02                 |0.64                  |\n",
      "|South Park         |6943.26                  |0.89                  |\n",
      "|West Vernon        |8722.73                  |1.07                  |\n",
      "|Chinatown          |14058.46                 |1.26                  |\n",
      "|Palisades Highlands|66867.44                 |0.21                  |\n",
      "|Glassell Park      |18824.3                  |0.5                   |\n",
      "|Boyle Heights      |8434.47                  |0.72                  |\n",
      "|Alsace             |11239.5                  |0.55                  |\n",
      "|Gramercy Place     |14936.7                  |1.08                  |\n",
      "|Tujunga            |22248.34                 |0.45                  |\n",
      "|Sherman Oaks       |37767.45                 |0.79                  |\n",
      "+-------------------+-------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Final results saved to: s3://groups-bucket-dblab-905418150721/group21/crime_population_analysis/"
     ]
    }
   ],
   "source": [
    "# Aggregate Final Results\n",
    "def aggregate_final_results(joined_spatial_df):\n",
    "    final_df = joined_spatial_df.groupBy(\"COMM\", \"TOTAL_POPULATION\", \"AVERAGE_INCOME_PER_PERSON\") \\\n",
    "        .agg(expr(\"count('*') as TOTAL_CRIMES\")) \\\n",
    "        .withColumn(\n",
    "            \"CRIME_RATIO_PER_PERSON\",\n",
    "            spark_round(col(\"TOTAL_CRIMES\") / col(\"TOTAL_POPULATION\"), 2)\n",
    "        ) \\\n",
    "        .select(\"COMM\", \"AVERAGE_INCOME_PER_PERSON\", \"CRIME_RATIO_PER_PERSON\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Aggregate using the default spatial joined DataFrame\n",
    "final_df = aggregate_final_results(joined_spatial_df_default)\n",
    "print(\"\\n=== Final DataFrame ===\")\n",
    "final_df.show(20, truncate=False)\n",
    "\n",
    "# Save the final results to CSV\n",
    "output_path = \"s3://groups-bucket-dblab-905418150721/group21/crime_population_analysis/\"\n",
    "final_df.coalesce(1).write.mode(\"overwrite\").csv(output_path, header=True)\n",
    "\n",
    "print(f\"\\nFinal results saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
